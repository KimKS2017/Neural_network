{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def sigmoid(z): # сигмоидальная (логистическая) функция\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# класс нейронной сети\n",
    "\n",
    "class Network:\n",
    "\n",
    "    def __init__(self, sizes, l1=0, l2=0): # инициализация нейронной сети\n",
    "        # len(size) - кол-во слоев нейронной сети, i-ый элемент списка sizes - кол-во нейронов на i+1 слое\n",
    "        self.num_layers = len(sizes) # задаем к-во слоев\n",
    "        self.sizes = sizes # задаем к-во нейронов на каждом слое\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]] # задаем начальный вектор смещения весов\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])] # задаем начальные веса\n",
    "        self.l1 = l1 # коэффициент для регуляризации L1\n",
    "        self.l2 = l2 # коэффициент для регуляризации L2\n",
    "\n",
    "        \n",
    "    def SGD(self, X, y, epochs, batch_size, learning_rate, eps):\n",
    "        # обучение нейронной сети методом стохастического градиентного спуска\n",
    "        error = True\n",
    "        i = 0\n",
    "        while error and i < epochs:\n",
    "            i += 1\n",
    "            error = False\n",
    "            indexes = list(range(len(X)))\n",
    "            sample_ind = np.random.choice(indexes, batch_size)\n",
    "            X_example = X[sample_ind]\n",
    "            y_answer = y[sample_ind]\n",
    "            self.update_mini_batch(X_example, y_answer, learning_rate)\n",
    "            error2 = self.error_function(X, y)\n",
    "            if error2 > eps:\n",
    "                error = True\n",
    "        return i, error, error2\n",
    "       \n",
    "        \n",
    "    def update_mini_batch(self, X_example, y_answer, learning_rate):\n",
    "        # один шаг градиентного спуска (т.е. обновление весов) по алгоритму обратного распределения ошибки  \n",
    "        # с возможностью использования регуляризации (по умолчанию коэффициенты регуляризации равны 0)\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x, y in zip(X_example, y_answer):\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "            \n",
    "        learning_rate_2 = learning_rate / len(X_example)\n",
    "        self.weights = [w - learning_rate_2 * nw - self.l1 * np.sign(w) - self.l2 * w for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases  = [b - learning_rate_2 * nb for b, nb in zip(self.biases,  nabla_b)]\n",
    "\n",
    "        \n",
    "    def backprop(self, x, y):\n",
    "        # вычисление градиента целевой функции\n",
    "        nabla_b_2 = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w_2 = [np.zeros(w.shape) for w in self.weights]\n",
    "        # прямое распределение: расчет активаций нейронов\n",
    "        a = []\n",
    "        z = x\n",
    "        a.append(z)\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = sigmoid(np.dot(w, z) + b)\n",
    "            a.append(z)            \n",
    "        # обратное распространение\n",
    "        # для выходного слоя\n",
    "        delta = (a[-1] - y) * a[-1] * (1 - a[-1]) \n",
    "        nabla_b_2[-1] = delta\n",
    "        nabla_w_2[-1] = delta.dot(a[-2].T)\n",
    "        # для остальных слоев\n",
    "        for l in range(2, self.num_layers):\n",
    "            delta = self.weights[-l+1].T.dot(delta) * a[-l] * (1-a[-l])\n",
    "            nabla_b_2[-l] = delta\n",
    "            nabla_w_2[-l] = delta.dot(a[-l-1].T)\n",
    "        return nabla_b_2, nabla_w_2\n",
    "    \n",
    "    \n",
    "    def error_function(self, X, y): # расчет значения функции ошибки\n",
    "        c = 0\n",
    "        for x, y_1 in zip(X, y):\n",
    "            a = x\n",
    "            for b, w in zip(self.biases, self.weights):\n",
    "                a = sigmoid(np.dot(w, a) + b)\n",
    "                y_answer = a\n",
    "                c += np.sum((y_1 - y_answer)**2)\n",
    "        return c / (2*len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# здесь будет реализован алгоритм считывания данных (после подключения источников)\n",
    "\n",
    "# X = \n",
    "# y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"разбиваем код на тестовую и обучающую выборки (желательный, но не обязательный шаг, использовать если достаточно данных)\n",
    "данное разбиение необходимо для сравнения качества работы нейронной сети при различных исходных данных и\n",
    "выбора оптимальной модели \"\"\"\n",
    "\n",
    "test_index = np.random.choice([True, False], len(X), replace=True, p=[0.25, 0.75])\n",
    "X_test  = X[test_index]\n",
    "y_test  = y[test_index]\n",
    "X_train = X[np.logical_not(test_index)]\n",
    "y_train = y[np.logical_not(test_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция расчета ошибки на тестовой выборке\n",
    "\n",
    "def error_function_for_test(X_test, y_test):\n",
    "        c = 0\n",
    "        for x, y_1 in zip(X_test, y_test):\n",
    "            a = x\n",
    "            for b, w in zip(n.biases, n.weights):\n",
    "                a = sigmoid(np.dot(w, a) + b)\n",
    "                y_answer = a\n",
    "                c += np.sum((y_1 - y_answer)**2)\n",
    "        return c / (2*len(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# запуск нейронной сети если есть тестовая выборка\n",
    "\n",
    "size = [2, 4, 5] # задаем \"размерность\" нейронной сети - к-во слоев и к-во нейронов на каждом слое\n",
    "\n",
    "\"\"\"инициализируем нейронную сеть, два последних параметра не обязательны, они задают коэффициенты регуляризации, \n",
    "по умолчания равны 0\"\"\"\n",
    "n = Network(size, 1, 1) \n",
    "\n",
    "B_start = n.biases # фиксируем стартовую точку градиентного спуска\n",
    "W_start = n.weights\n",
    "\n",
    "i, error, error2 = n.SGD(X_train, y_train, epochs=100, batch_size=2, learning_rate=1, eps=0.01) # обучаем нейронную сеть\n",
    "print (i, error, error2)\n",
    "\n",
    "B = n.biases # фиксируем результаты работы нейронной сети\n",
    "W = n.weights\n",
    "\n",
    "error3 = error_function_for_test(X_test, y_test) # тестируем эффективность нейронной сети \n",
    "print(error3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# запуск нейронной сети если нет тестовой выборки\n",
    "\n",
    "size = [3, 2, 1] # задаем \"размерность\" нейронной сети - к-во слоев и к-во нейронов на каждом слое\n",
    "\n",
    "\"\"\"инициализируем нейронную сеть, два последних параметра не обязательны, они задают коэффициенты регуляризации, \n",
    "по умолчания равны 0\"\"\"\n",
    "\n",
    "n = Network(size, 1, 1) \n",
    "\n",
    "B_start = n.biases # фиксируем стартовую точку градиентного спуска\n",
    "W_start = n.weights\n",
    "\n",
    "i, error, error2 = n.SGD(X, y, epochs=10000, batch_size=100, learning_rate=1, eps=0.01) # обучаем нейронную сеть\n",
    "print (i, error, error2)\n",
    "\n",
    "B = n.biases # фиксируем результаты работы нейронной сети\n",
    "W = n.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
